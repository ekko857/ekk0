setwd("Documents/CMEECourseWork/PROJECT")
getwd()
setwd("/Users/3kko/Documents/CMEECourseWork/PROJECT")
data <- readRDS("data/16S/ps_16S_cESVs_clean_Ransome.RDS")
se_score <- readRDS("Data/Stress_datasets/RESET_SE_score_Ransome.RDS")
reset_score <- readRDS("Data/Stress_datasets/RESET_cumul_score_Ransome.RDS")
human_data <- read.csv('data/Stress_datasets/FR_AnthroStress_Biogeo_data_Ransome_15042024.csv')
hill_numbers <- read.csv("data/hill_numbers.csv", row.names = 1)
sample_data <- sample_data(data)
sample_data <- as.matrix(sample_data)
sample_data <- as.data.frame(sample_data)
sample_data$sample_name <- rownames(sample_data)
hill_numbers_with_sample <- left_join(hill_numbers, sample_data, by = 'sample_name')
otu <- otu_table(data)
otu <- as.matrix(otu)
otu <- as.data.frame(otu)
# 计算每个 eventID 和 variable 下的 SE_score 的均值
# 清洗数据，去除缺失值
se_score_clean <- se_score %>% filter(!is.na(SE_score))
#加载数据
setwd("/Users/3kko/Documents/CMEECourseWork/PROJECT")
data <- readRDS("data/16S/ps_16S_cESVs_clean_Ransome.RDS")
library(randonforest)
library(randomforest)
library(randomForest)
#加载数据包
library(tibble)
library(vegan)
library(phyloseq)
library(dplyr)
library(ggplot2)
library(mgcv)
library(forecast)
library(broom)
library(gridExtra)
library(cowplot)
library(randomForest)
#加载数据
setwd("/Users/3kko/Documents/CMEECourseWork/PROJECT")
data <- readRDS("data/16S/ps_16S_cESVs_clean_Ransome.RDS")
####计算hill number
otu <- as.matrix(otu_table(data))
otu <- as.data.frame(otu)
head(otu)
class(otu)
##calculate total abundance
total_counts <- colSums(otu)
##calculate Relative abundance
rel_abundance <- sweep(otu, 2, total_counts, "/")
#define a function for calculation of Shannon entropy
shannon_entropy <- function(p) {
p <- p[p > 0]      # only do calculation when p > 0
-sum(p * log(p))   # formular
}
#define a function for calculation of Hill number
hill_number <- function(p, q) {
if (q == 1) {
return(exp(shannon_entropy(p)))
} else if (q == 0) {
return(sum(p > 0))  # ignore 0 (means no such species exists)
} else {
return((sum(p^q))^(1/(1-q)))
}
}
# calculate hill number for each samples
hill_numbers <- apply(rel_abundance, 2, function(p) {
c(N0 = hill_number(p, 0),  # species richness (q = 0)
N1 = hill_number(p, 1),  # The exponential form of Shannon entropy (q = 1)
N2 = hill_number(p, 2))  # The reciprocal of Simpson's diversity (q = 2)
})
#save data as csv
hill_numbers <- as.data.frame(t(hill_numbers))
write.csv(hill_numbers, 'data/hill_numbers.csv')
setwd("/Users/3kko/Documents/CMEECourseWork/PROJECT")
data <- readRDS("data/16S/ps_16S_cESVs_clean_Ransome.RDS")
se_score <- readRDS("Data/Stress_datasets/RESET_SE_score_Ransome.RDS")
reset_score <- readRDS("Data/Stress_datasets/RESET_cumul_score_Ransome.RDS")
human_data <- read.csv('data/Stress_datasets/FR_AnthroStress_Biogeo_data_Ransome_15042024.csv')
hill_numbers <- read.csv("data/hill_numbers.csv", row.names = 1)
sample_data <- sample_data(data)
sample_data <- as.matrix(sample_data)
sample_data <- as.data.frame(sample_data)
sample_data$sample_name <- rownames(sample_data)
hill_numbers_with_sample <- left_join(hill_numbers, sample_data, by = 'sample_name')
otu <- otu_table(data)
otu <- as.matrix(otu)
library(foreach)
library(parallel)
library(doParallel)
# this function calculates the Shannon entropy of a given set of frequencies
shannon_entropy <- function(frequency) {
proportions <- frequency/sum(frequency)
entropy <- 0
for (pi in proportions) {
if (pi > 0) {
entropy <- entropy - (pi * log(pi))
}
}
return(entropy)
}
# this function produces a discretized log normal distribution in arithmetic space
discretised_lnorm <- function(mean,sd) {
# the max variable gives us the maximum value we'll consider
max <- floor(exp(mean + sd*4))+1
# the missed_zero approximates what we've missed as it lies on or below zero abundance
missed_zero <- plnorm(0.5,mean,sd)
# store the result
lnorm_result <- dlnorm(1:max,mean,sd)
# normalize
lnorm_result <- lnorm_result/(sum(lnorm_result)+missed_zero)
return(lnorm_result)
}
# this function sums to vectors of different lengths
sum_vect <- function(x,y) {
if (length(x)==length(y)) {
return(x+y)
} else {
if (length(x)<length(y)) {
return(c(x,rep(0,length= (length(y)-length(x))))+y)
} else {
return(c(y,rep(0,length= (length(x)-length(y))))+x)
}
}
}
# this function computes Bibury diversity
bibury <- function(frequency,param) {
abundance_kernel <- c()
for (i in frequency) {
abundance_kernel <- sum_vect(abundance_kernel,discretised_lnorm(log(i),param))
}
bibury_diversity <- shannon_entropy(frequency) + shannon_entropy(abundance_kernel)
return(bibury_diversity)
}
# 5. 计算每个样本的 Bibury 多样性指数
# 设置标准差参数
param <- 0.5
# 6. 设置并行计算环境
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
# 导出必要的函数和变量到集群
clusterExport(cl, c("shannon_entropy", "discretised_lnorm", "bibury", "sum_vect", "param"))
#并行计算 Bibury 多样性指数
# 9. 并行计算 Bibury 多样性指数
# 9. 并行计算 Bibury 多样性指数
bibury_diversities <- foreach(i = 1:ncol(otu), .combine = c, .packages = c("base", "parallel")) %dopar% {
frequency <- as.numeric(otu[, i])
frequency <- frequency[frequency > 0]  # 筛选掉零值
if (length(frequency) > 0) {
return(bibury(frequency, param))
} else {
return(NA)  # 如果所有值都为零，返回 NA
}
}
write.csv(hill_numbers, 'data/hill_numbers.csv')
hill_numbers$sample_name <- colnames(hill_numbers)
write.csv(hill_numbers, 'data/hill_numbers.csv')
hill_numbers$sample_name <- rownames(hill_numbers)
write.csv(hill_numbers, 'data/hill_numbers.csv')
sample_data <- sample_data(data)
sample_data <- as.matrix(sample_data)
sample_data <- as.data.frame(sample_data)
sample_data$sample_name <- rownames(sample_data)
hill_numbers_with_sample <- left_join(hill_numbers, sample_data, by = 'sample_name')
otu <- otu_table(data)
otu <- as.matrix(otu)
otu <- as.data.frame(otu)
# 计算每个 eventID 和 variable 下的 SE_score 的均值
# 清洗数据，去除缺失值
se_score_clean <- se_score %>% filter(!is.na(SE_score))
mean_se_score <- se_score_clean %>%
group_by(eventID, variable) %>%
summarise(mean_SE_score = mean(SE_score, na.rm = TRUE), .groups = "drop")
hill_numbers_with_stress <- left_join(hill_numbers_with_sample, result, by = "eventID")
# 计算每个 eventID 和 variable 下的 SE_score 的均值
# 清洗数据，去除缺失值
se_score_clean <- se_score %>% filter(!is.na(SE_score))
mean_se_score <- se_score_clean %>%
group_by(eventID, variable) %>%
summarise(mean_SE_score = mean(SE_score, na.rm = TRUE), .groups = "drop")
# 进行双重指数平滑处理
data_smoothed <- reset_score %>%
group_by(eventID) %>%
arrange(eventID) %>%
do({
ts_data <- ts(.$RESET_score, start = 1, frequency = 1)
fit <- HoltWinters(ts_data, beta = TRUE, gamma = FALSE)  # 双重指数平滑
smoothed <- as.data.frame(fit$fitted)
smoothed_RESET_score <- c(rep(NA, length(ts_data) - nrow(smoothed)), smoothed$xhat)
data.frame(eventID = .$eventID, smoothed_RESET_score)
})
# 计算每个 eventID 的 smoothed_RESET_score 均值
result <- data_smoothed %>%
group_by(eventID) %>%
summarise(mean_smoothed_RESET_score = mean(smoothed_RESET_score, na.rm = TRUE))
hill_numbers_with_stress <- left_join(hill_numbers_with_sample, result, by = "eventID")
hill_numbers_with_human <- left_join(hill_numbers_with_sample, human_data, by = 'eventID')
hill_numbers_with_se <- left_join(hill_numbers_with_sample, mean_se_score, by = 'eventID')
# 进行双重指数平滑处理
data_smoothed <- reset_score %>%
group_by(eventID) %>%
arrange(eventID) %>%
do({
ts_data <- ts(.$RESET_score, start = 1, frequency = 1)
fit <- HoltWinters(ts_data, beta = TRUE, gamma = FALSE)  # 双重指数平滑
smoothed <- as.data.frame(fit$fitted)
smoothed_RESET_score <- c(rep(NA, length(ts_data) - nrow(smoothed)), smoothed$xhat)
data.frame(eventID = .$eventID, smoothed_RESET_score)
})
# 计算每个 eventID 的 smoothed_RESET_score 均值
result <- data_smoothed %>%
group_by(eventID) %>%
summarise(mean_smoothed_RESET_score = mean(smoothed_RESET_score, na.rm = TRUE))
# 显示图形
print(combined_plot)
model_N0 <- lm(N0 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress)
model_N1 <- lm(N1 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress)
model_N2 <- lm(N2 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress)
summary(model_N0)
summary(model_N1)
summary(model_N2)
# 获取模型摘要并转换为数据框
summary_N0 <- tidy(model_N0)
summary_N1 <- tidy(model_N1)
summary_N2 <- tidy(model_N2)
# 添加响应变量列以区分数据
summary_N0$Response <- "N0"
summary_N1$Response <- "N1"
summary_N2$Response <- "N2"
# 合并数据
summary_all <- rbind(summary_N0, summary_N1, summary_N2)
write.csv(summary_all, 'summary_reset.csv', row.names = FALSE)
# 输出数据框
print(summary_all)
# 预测 N0, N1, N2
hill_numbers_with_stress$predicted_N0 <- predict(lm(N0 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress))
hill_numbers_with_stress$predicted_N1 <- predict(lm(N1 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress))
hill_numbers_with_stress$predicted_N2 <- predict(lm(N2 ~ mean_smoothed_RESET_score * sampleSizeFractionation, data = hill_numbers_with_stress))
# 绘制 N0 的图
plot_N0 <- ggplot(hill_numbers_with_stress, aes(x = mean_smoothed_RESET_score, y = N0, color = sampleSizeFractionation)) +
geom_point() +
geom_line(aes(y = predicted_N0), linetype = "dashed") +
labs( x = "Mean RESET Score", y = "N0") +
scale_color_manual(name = "Sample size Fractionation",   # 更改图例标题
values = c("100" = "#ff5575", "500" = "#14bc94", "sessile" = "#6299ff"), # 示例颜色映射
labels = c("100" = "100 μm", "500" = "500 μm", "sessile" = "Sessile")) +
theme_minimal() +
theme(plot.background = element_rect(fill = "white", color = "white"),
panel.background = element_rect(fill = "white", color = "white"))
# 绘制 N1 的图
plot_N1 <- ggplot(hill_numbers_with_stress, aes(x = mean_smoothed_RESET_score, y = N1, color = sampleSizeFractionation)) +
geom_point() +
geom_line(aes(y = predicted_N1), linetype = "dashed") +
labs(x = "Mean RESET Score", y = "N1") +
scale_color_manual(name = "Sample Size Fractionation",   # 更改图例标题
values = c("100" = "#ff5575", "500" = "#14bc94", "sessile" = "#6299ff"), # 示例颜色映射
labels = c("100" = "100 μm", "500" = "500 μm", "sessile" = "Sessile")) +
theme_minimal() +
theme(plot.background = element_rect(fill = "white", color = "white"),
panel.background = element_rect(fill = "white", color = "white"))
# 绘制 N2 的图
plot_N2 <- ggplot(hill_numbers_with_stress, aes(x = mean_smoothed_RESET_score, y = N2, color = sampleSizeFractionation)) +
geom_point() +
geom_line(aes(y = predicted_N2), linetype = "dashed") +
labs(x = "Mean RESET Score", y = "N2") +
scale_color_manual(name = "Sample Size Fractionation",   # 更改图例标题
values = c("100" = "#ff5575", "500" = "#14bc94", "sessile" = "#6299ff"), # 示例颜色映射
labels = c("100" = "100 μm", "500" = "500 μm", "sessile" = "Sessile")) +
theme_minimal() +
theme(plot.background = element_rect(fill = "white", color = "white"),
panel.background = element_rect(fill = "white", color = "white"))
# 将三个图合并在一个图中
p1 <- grid.arrange(plot_N0, plot_N1, plot_N2, ncol = 1)
ggsave("plot1.png", plot = p1, width = 10, height = 8, units = "in", dpi = 300)
